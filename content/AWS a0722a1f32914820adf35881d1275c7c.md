# AWS

<aside>
💡 Daha temel olarak bile öğrenecek çok servis var

</aside>

## Architecture

İki temel yapıdan oluşur:

- Region: Dünyadaki bölgelerdir.
- Availability zone: Bölgelerdeki server center’lerdir. Örneğin bir region birden fazla availability zone’a sahip olabilir.

# Service Domains

### 1. **Compute**

- **EC2**
    
    **Bidiğimiz sanal makinelerdir. Ancak gelen veri miktarına, cpu gereksinimlerine… göre kendisini up/down scale edebilir. Bu yüzden esnektir. Uygulamamızı up scale etmemiz gerektiğinde yeni instance’ler almak yerine tek instance’ta scale yaparak const efficiency sağlar.**
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled.png)
    
    ### **Instance Types**
    
    1. General Purpose
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%201.png)
    
    1. Compute instance
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%202.png)
    
    1. Memory instance
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%203.png)
    
    1. Storage instances
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%204.png)
    
    1. Gpu instance
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%205.png)
    
    ### Pricing Models
    
    1. On-demand: Kullanıcının isteklerine göre kiralama yapılan modeldir. Örneğin, benim için 1 saatliğine kirala.
    2. Dedicated: Bu sanal makineler kimseyle paylaşılmaz. Veriler normalde zaten güvendedir ama örneğin bir firmaysanız ve verileriniz sizin için çok önemliyse ki öyledir, kendinize özel bir alan ayırarak sanal makineler kullanırsınız.
    3. On-spot: Açık artırma ile sunucu kiralamak gibi bir şey. Bazı instance’ler açık artırmaya çıkar. En yüksek fiyatı veren kiralar. Ancak bu sunucuda depolama yapılamaz. Sadece uçucu veriler saklanır. Çünkü kiralanan süre bittiğinde verilere ulaşmak mümkün olmayacaktır.
    4. Reserved: Tamamen size ayrılmış bir sanal sunucu(instance) verir. Ne cpu’sunu ne de başka bir şeyini başkası kullanamaz. Bir ev kiralamak gibi
    
    <aside>
    💡 EC2’ler bir VPC olmadan internete bağlı olamazlar hatta var olamazlar. Bir aws hesabında default bir vpc olduğu için EC2’ler oluşturulabilir.
    Bir EC2’nin internet giriş çıkış ayarlarını (port vs.) yönetmek için security group’ları düzenlemek gerekir. Security group’lar ise subnet’lere bağlıdır. Yani EC2’nin bağlı olduğu VPC’nin security group’ları kullanılır.
    
    </aside>
    
- **Elastic Beanstalk**
    
    > EC2’nin otomatize edilmiş şeklidir.
    > 
    - Bir sanal makinenin, bir uygulama için gerekli bütün ortamı hazır olarak sağlanır.
    - Ek olarak monitoring, load-balancer, security group araçları da gelir.
    - Gelen yüke göre auto-scale olur.
    - Ek olarak verilen şeyler için bir ücret ödenmez. Sadece harcanan kaynaklar için ücret ödenir.
    - Web hosting için kullanılır.
    - İstenildiği zaman infrastructure’de değişiklik yapılabilir
    
    **Bazı Kavramlar**
    
    Application version: Git’te olduğu gibi beanstalk’te yapılan her değişiklik versiyonlanır. Her değişikliğin yeni bir kopyası oluşturulur
    
    Application environment: Farklı çevreler oluşturulur. Yani örneğin development için farklı, test için farklı prduction için farklı bir ortam oluşturabiliriz.
    
    Environment health: Environment’in durumu 4 farklı renklerle sembolize edilir.Passed, failed, heavy failed, being updated
    
    ---
    
    Beanstlk Web server aynı anda sadece bir environment çalıştırabilir. Bu environment, otomatik olarak isteklere göre scale olur. Eğer trafik yüksek ise ve kapasite yetmediyse başka bir instance daha kullanıma açılır ve gelen istekler o instance tarafından da işlenir. Eğer kullanılacak bir ec2 instance yoksa yeni instance’ler oluşturulur ve kullanılır. O instance’lere de gerekli uygulamalar yüklenir. Ama bu işlemler için kulanıcı hiçbir işlem yapmaz. Beanstalk bunu kendisi yönetir. Beanstalk isteklerin ve işlemlerin ve metriklerin loglarını tutar(host manager). Ayrıca Security Group’lar tarafından güvenlik duvarı ve izinler yönetilri. Default olarak 80 portu açıktır.
    
    Beanstalk Worker server, worker’ları barındıran farklı bir environmenttir. CPU-intensive ya da time-consuming bir istekle karşılaşırsa bu isteği bir SQS(simple queue service) yardımıyla bir worker server’a geçer. Worker-server’da işlem tamamlanınca tekrar SQS yardımıyla web server’a cevap gelir. Werb server da cevabı clienta döndürür.
    
    ---
    
    Bir environment oluşturulurken bir domain seçilir. Bu domain eşsizdir ve aslında web server’in url adersidir. local bir uygulamada server için [http://localhost:3000](http://localhost:3000) adresine istek atıyorsak aslında bu domain de o işe yarar.
    
    ---
    
    Konfigürasiyonlar menüsüne gelerek instance tipi değiştirebiliriz. Örneğin t2xlarge gibi
    
- **Lambda**
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%206.png)
    
    - İşletim sistemine erişim yetkisi yoktur.(no worries about infrastruct)
    - Bir uygulama deploy edip çalıştırılamaz. EC2 ve Beanstalk arasındaki ana fark budur. Bunun yerine, verilen arkaplan görevlerini yapar.
    - İsteiğimiz konfigürasyonu seçemeyiz. İş yükümüze göre Lambda bize gerekli altyapıyı sağlar ve konfigürasyonu yapar.
    - Lambda, içinde container’ler barındırır. İş yüküne göre container sayısı azaltılır ya da artırılır. Container’ler içerisinde, ihtiyaç duyulan bütüm bağımlılıklar vardır.
    - EC2 durdurulup başlatılır ancak Lambda’nın böyle bir yapısı yoktur. İstenilen fonksiyon çağrıldığında çalışır ve biter yani event-driven’dir.
    
    > Diyelim ki bir blog sitemiz var. Bu blog sitemizde gelen isteklerden profil resmi eklemeyi ele alalım. Profil fotoğraflarını işleyip S3’te depolamak istiyoruz. İşte bu işemi bir lambda fonksiyonu olarak yapıyoruz. Böylece artık bu işlem AWS’nin kendi sunucularında yapılacak ve bize sadece istediğimiz sonucu döner.
    > 
    
    > Genelde medya işleme, yedek alma, verileri analiz etme gibi işlemler için kullanılır. Mail gönderme işlemi için de kullanılabilir mesela.
    > 
    
    **NodeJs ile nasıl kullanılır?**
    
    [AWS Lambda with Node.js: A Complete Getting Started Guide](https://stackify.com/aws-lambda-with-node-js-a-complete-getting-started-guide/)
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%207.png)
    
    > Yukarıdaki görselin özeti:
    - Bir lambda 3 gb’dan daha büyük memory kullanamaz.
    - Bir lambda en fazla 15 dakika boyunca çalışır. 15 dakikadan sonra fonksiyon durur
    - 100 milisaniyeye kadar bir gecikme olabilir.
    Eğer bunlar sizin uygulamanız için önemli kısıtlarsa bunun yerine EC2 tercih etmelisiniz.
    > 

> AWS serverless ekosistemini nodejs’te kullanmak için **serverless** framework’ü npm paketi olarak kurulur. Github’a nasıl erişiyorsak AWS hesabına da aynı şekilde gerekli config’lerin ardaından erişebiliriz. Böylece lambda fonksiyonlarına erişebiliriz.
> 

> IAM: AWS hesabının root kullanıcı dışında erişim iznine sahip olan kullanıcılardır. Kendilerine verilen bir id ve access key ile giriş yaparlar. AWS programmatic management yetkisine sahip olurlar yani CLI’lar üzerinden AWS heabına erişebilirler. Ancak istenirse AWS anagement console’a da giriş yetkileri verilebilir.
> 

### 2. Strorage

- **EFS(elastic file system)**
    
    Sadece EC2’nin kullanabildiği bir depolama sistemidir. Boyutu, scale olabilir.
    
- **EBS(elastic block storage)**
    
    Bildiğimiz sabit disklerdir. Sadece EC2 ile kullanılabilir. Boyutu sabittir. EC2 instance’sine attach olarak kullanılabilir.
    
- **S3 (simple storage service)**
    - AWS’nin temel depolama sistemidir. Her türlü dosya barınıdırılabilir. Erişim hızı yüksektir. Dosyalar, klasörleme şeklinde tutulur. Her bir s3 instance’sine bucket adı verilir.
    
    > Versinoning: S3’teki herhangi bir dosyada değişiklik yapıldığında Git’te olduğu gibi, değişiklik yapılan bir önceki dosya silinmez. Değişiklik yapılmış dosya da sistemde kaydedilir. Bu iki dosyanın ismi aynıdır ancak versiyon numaraları farklıdır. Bu özellik başlangıçta kapalıdır, açmak gerekir. Yanlışlıkla dosya silinmesinin de önüne geçilmiş olur.
    > 
    - Lifecycle rule: Versioning açık olduğu durumda, versiyonların diğer bir S3 tipine geçmesine izin verir. Mesela şunu diyebiliriz: Create edildikten 30 gün sonra eski versiyonları, Glacier tipindeki S3’e taşı.
    - Region replication: Bucket’taki verileri bir başka bölgedeki bucket’a(illa bizim bucket’imiz olmasına gerek yok) replika etmek
    
    <aside>
    💡 Infrequent tipinde bir S3 vardır. Bu, S3 ve Gracier arasında bir erişim süresine sahiptir.
    
    </aside>
    
    > S3 transfer acceleration: Bir dosyanın çekilme esnasında eğer S3, çekecek kişiye uzaksa bir yavaşlık oluşabilir. Bunun için S3 transfer acceleration kullanılır.
    > 
    
    <aside>
    💡 Bucket policy oluşturulabilir. Böylece gelen isteklerde istek yapan kişinin yetkis iyoksa işlem gerçekleşmez.
    
    </aside>
    
- **S3 Glacier**
    
    S3’ün bir sınıfıdır ama farklı bir servis olarak ayrılmıştır.
    
    Sürekli olarak ihtiyaç olmayan verileri tutmak için kullanılır. Arşiv olarak adlandırılır. Çünkü arşivdeki kayıtlara sürekli ihtiyacımız olmaz. Nadiren gider ve bakarız. İşte bu yüzden S3 Glacier’in arama hızı düşüktür.
    

### **3. Networking**

- **VPC**
    
    AWS servislerini barındıran bir sanal ortamdır. Ben bunu Docker network’lere benzetiyorum ki belki de altyapısı Docker ile yapılıyordur 🙂
    
    Amazon, her kullanıcıya her bir region’da default bir VPC atar. Biz frankfurt regionundaki VPC’yi ele alalım. Bir region’da birden fazla data center yani availability zone vardır. Diyelim ki frankfurtta 3 data center var(bu zonelar arası mesafe 60-100km arası değişir). Her bir zone içerisinde farklı subnet’ler olur. Örneğin her zone başına bir private bir public olmak üzere 2 subnet ayırırsak toplam 3*2=6 tane subnet’imiz olur. Ama bu subnetleri biz kendi şart ve kaynaklarımıza göre farklı olarak ayarlayabiliriz. Peki bunu neden yapıyoruz? Tek bir subnet olsa ne olur ki?
    
    Diyelim ki biz sadece bir zone’a subnet koymuşuz. Bir server’imiz var ve istekler bu subnet üzerinden geliyor. Eğer bir zone’da bir sıkıntı yaşanırsa diğer zone’lar üzerinde uygulama hala çalışır halde olacak ve oralardan trafik alınabilecek.
    
    Örnekte subnet’lere public ve private ismini verdik diye bu subnet’ler public ve private olmaz. Bunların public ve private olmasını biz, internet gateway’ler yoluyla internete açılmasındaki route table’lar yoluyla internete çıkış tanımlarından, rotalarından belirliyoruz.
    
    Publi gateway’lerimizi internet gateway ile el sıkışarak internete çıkartıyoruz. Private gateway’lerimizi ise NAT Gateway’lerimiz ile internete çıkarıyor, girişleri blokluyoruz.
    
    İki subnet’in konuşabilmesi için route table’da bir tanım olması gerekir.
    
    Internet gateway’i VPC’ye attach ediyoruz. Subnet’lerin internet çkışılarını internet gateway’e giriş olarak verdiğimiz az önce bahsettiğimiz subnet’ler gerçekten public oluyor.
    
    NAT gateway’lerimizi ise herbir public subnet’e koyarız. Bunlar sayesinde subnet’ler internete çıkar. Peki neden herbirine koyuyoruz? Tek birine koysak olmaz mıydı? Elbette olurdu. Bu, bizim tasarımımıza kalmış bir şey. Ancak bunu, high-availability için yapıyoruz. Böylece bir zone’a bir şey olduğunda diğer subnet’ler internete çıkabilir. Private subnetten, internete çıkmak isteyenler nat gateway’e gelir. Nat gateway’ler de internet gateway’ler vasıtasıyla internete çıkar.
    
    Network ACL(access control list) ve security grouplar ise hangi resource’lara erişilip erişilemeyeceğini belirler.
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%208.png)
    
- **Direct Connect**
    
    Verilerin public internet üzerinden gitmesi yerine private tunnel oluşturarak verilerin gizliliğini sağlar. Private VPN ile farkları vardır. VPN, public internet üzerinden şifreli bir bağlantı kurarken, direct connect yalnıza iki tarafın kullanabileceği ek bir sabit ağ kurar.
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%209.png)
    
- **Route53**
    
    Trafiği redirect yapar. Bir domainden yapılan istekleri bir aws servisine(bu servis elbette her şey olmaz. Örneğin API Gateway ya da cloudfront…) yönlendirir. Bu servisten emin değilim. Yanlış da anlamış olabilirim. Netflix falan kullanıyormuş.
    GoDaddy, Namecheap gibi basit DNS servisleri ya da Cloudflare’in DNS servisinden farkı Route53’ün dinamik olmasıdır. IP adresiniz değişse bile domain’iniz değişmez. Ayrıca örneğin bir server çökmesi anıda Route53 ile domain server’e gelen istekleri otomatik olarak başka bir sunucunuza yönlendirebilirsiniz.
    
- **CloudFront**
    
    Örneğin Amerika’dan Avusturalya’ya bir web sitesi için bir istek attığımızda web sitesindeki içerikler taaaa Avusturalyadan gelir. Ve direkt olarak gelmez. Cloudfront ise bizim için belli bölgelere **edge location**slar kurar. Avusturalya’daki sitemizdeki içerikler bize yakın olan edge locationslarda cache’lenir.
    
    End user, verinin bulunduğu bir server’a bir istek gitmek istediğinde önce edge location’lara gider. Eğer orada varsa yani daha önceden cache’lenmiş ise alır getirir. Eğer yoksa ana server’a gider. Oradan alarak cache’leyip edge location’a yazar. Sonra kullanıcıya veriyi döner.
    
    Cloudfront oluşturulduğunda, bu servisin hangi servise referans edeceği seçilir. Örneğin CDN olarak S3 servisini kullanacaksak onu seçeriz. Eğer S3 bucket’inin tamamını değil de içindeki bir klasörü serve edeceksek onu seçeriz. Gerekli custom ayarları yapabilir ve cloudfront oluştururuz. Oluşturulduktan sonra bize eşsiz bir isim verir. Örneğin:
    
    ```jsx
    nb12v3b12p3123lk.cloudfront.net
    ```
    
    Bu adresi kullanarak direkt olarak verileri buradan fetch edebiliriz. Bence her ne kadar doğru bir davranış olmasa da CRUD işlemlerini de bu adresten yapabiliriz. Ama bunu ayarlardan seçmek gerekir. Örneğin bootstrap CDN’den CSS dosyasını çektiğimiz gibi client tarafında resimleri gösterirken örneğin şu şekilde kullanılırsa cloudfront bence başarılı olur: 
    
    ```jsx
    http://nb12v3b12p3123lk.cloudfront.net/avatar/user-id.jpg
    ```
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2010.png)
    
- API Gateway
    
    REST ya da HTTP API sağlar. Serverless mimarisi dahilinde kullanılır genelde
    

### **4. Monitoring and Management**

- **Cloudwatch**
    
    > **Monitoring tool nedir? Ne işimize yarar?**
    > 
    > 1. Uygulamadaki kullanıcıların neler yaptığını ve trendleri izlemek. Örneğin bir mesajlaşma uygulamanız var. Kullanıcıların neler yaptığını, en çok hangi işlemlerin yapıldığını, hangilerinin daha az kaynak harcadığını izleyebilir ve böylece uygulamaya yön verebiliriz.
    > 2. Server’in işlem yapmadığı zamanlarda izleyerek down-scale yapmak ya da kapatmak. Bir uygulamanız var ve bu uygulama geceleri işlem yapmıyorsa ya da çok az yapıyorsa bunu izleyerek geceleri uygulamanızı kapatabilir ya da down-scale edebilirsiniz. Böylece maliyetten kurturulursunuz.
    > 3. Çalışan sisteminiz aniden çökerse bunun sebebini monitoring tool sayesinde kolayca bulup uygulamayı fix edebilirsiniz. Örneğin bir e-ticaret siteniz varsa çökme anında başka sitlere gidebilecek potansiyel müşterileri kaybetmemiş olursunuz.
    
    <aside>
    💡 Cloudwatch ile şunlar yapılabilir:
    
    - ile trendleri yani kullanıcı hareketleri izlenebilir.
    - sistem performansını izlenebilir
    - Sisteme erişimlerini log dosyalarını depolanabilir
    - Alarmlar kurabilir ve bildirimler gönderilir
    - SNS topics, lambda functions gibi aws resource’larına event’ler gönderilebilir.
    </aside>
    
    Cloudwatch aslında bir **metrik** deposudur.
    
    **Metrik**; herhangi bir amazon servisinin(EC2, EBS, load balancer…) verileridir(örneğin cpu, memory, network kullanımı…).
    
    Her bir metrik **dimensionlara** sahiptir. Her bir metriğin farklı açılardan değerlendirmesi gibi düşünülebilir. X metriğinin Y dimension’u ve Z dimension’u gibi. Dimension’lar, metrikleri eşsiz isimlere sahip kılan bir key-value çifti gibidir. Böylece her dimension için bir tablo oluşturulur.
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2011.png)
    
    İstatistikler ise toplanan metriklerin tablolarının birleştirilmesinden oluşan bir tablodur.
    
    Alarmlar sayesinde, belirlenen metrik değerleri belirlenen değerlere ulaştığında bildirim gönderilir ve kullanıcı haberdar edilir ya da diğer aws servisleri tetiklenebilir
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2012.png)
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2013.png)
    
    <aside>
    💡 Cloudwatch’ta bir metrik izlenir. Eğer o metrikte bir değer aşılırsa ya da bir anomalı gerçekleşirse SNS topic’ine bilgi gönderilir. SNS topiği de subscriber’lere bildirim gönderir.
    
    </aside>
    
    **CloudWatch Events**
    
    Bir AWS servisinde bir değişiklik olduğunda Cloudwatch events sayesinde bundan haberdar olup gerekli aksiyonları alabiliriz. Lambda function bir SQS’teki değişiklikleri farkedip nasıl aksiyon alıyorsa CloudWatch’de aslında bir AWS servisinde olan bir değişikliği farkedip ona göre bir işlem yaptırabilir.
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2014.png)
    
    Yukarıdaki use case’de bir ec2 server’i kapanırsa cloudwatch event sayesinde bir lamba function’u çalışarak kapanan server’in dns kaydını route53’ten siler.
    
    Diğer bir use-case ise: Bir EC2 instance’sini kapamak açmak ya da herhangi yapılması gereken bir işi zamanlamak. Yapılması gereken işin lambda fonksiyonu oluşturulur. Bu lambda fonksiyonu cloudwatch alarmı sayesinde her gün saat 6’da çalışmak üzere ayarlanabilir. cloudWATCH 😃 
    **CloudWatch Logs**
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2015.png)
    
- **CloudFormation**
    
    Cloudformation, bir JSON/YAML dosyası ile aws kaynaklarını tek bir elden kolayca yönetmeyi sağlayan bir servistir. Bir json dosyası içine, proje ya da uygulamada kullanılacak olan servisler ve bunların konfigürasyonları ve security group’ları yazılır. Bütün bu ayarlardan sonra bir stack oluşturulmuş olur. Bu stack, bir S3 bucket olarak depolanır. İstendği zaman stack silinerek, stack’e bağlı kaynakların da silinnmesi sağlanır.
    
    Json dosyası içinde şu bilgiler yer alabilir:
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2016.png)
    
    Parameter olarak servislerde kullanılacak olan bilgiler girilir. Örneğin DB name, DB password, ssh keys…
    
    Bu servis bir json dosyasından ibaret olsa da json dosyasına ihtiyaç duyulmadan drag-drop yöntemiyle de kolayca stack oluşturulabilir.
    
    Clıudformation sayesinde kolaylıkla bir EC2 oluşturulup içinde Nodejs ve gerekli bağımlılıklar kurularak uyglama ayağa kaldırılabilir.
    
    Aslında cloudformation’u docker-compose ya da CI/CD dosyalarına benzetebiliriz. Docker compose dosyasında da gerekli servisleri sağlayarak uygulamayı up edebiliriz.
    
    Benzer şekilde örneğin Gitlab CI dosyasında da uygulama kurulduktan sonra server içinde çalıştırılacak kodları yazabiliyoruz. Cloudformation’da da EC2 kurup içine kodlar yazarak kurmak istediklerimizi kurarız
    
    **Peki ben CloudFormation’u nerede kullandım?**
    
    Serverless framework’te kullandım. Serverless.yml dosyasına yazılan kodlar deploy edildiğinde aslında bir cloudformation stack oluşturulur ve serverless.yml dosyası ile o stack json dosyasını yönetiriz. AWS SAM de benzer mantıkla çalışmaktadır.
    

<aside>
💡 **Snapshot**: Bir EC2 server’indeki dataların anlık bir kopyasını almaktır. Bu kopyalanana data bir EBS volume’sinde tutulur. Bir server kurulduğunda bunun bağımlılıklarını yüklemek zaman alır. Bunun için kurduktan sonra bunun bir kopyasını alırsak server’a bir şey olursa tekrar kurmak zorunda kalmayız.

</aside>

<aside>
💡 AMI(Amazon Machine Image): Bir EC2 server’inin anlık kopyasını almaktır. Snapshot’tan farkı çalıştırılabilir olmasıdır. Bir EC2 server nasıl up edilebiliyorsa bir AMI de up edilebilir.

</aside>

- **AutoScaling**
    
    **AWS Auto Scaling ve AWS Auto Scaling Grupları**
    
    AWS Auto Scaling, uygulama düzeyinde ölçeklendirme için hizmet verir. Bu hizmet sayesinde uygulamanız otomatik olarak yüksek kullanım yoğunluğu sırasında daha fazla kaynak alır veya düşük kullanım yoğunluğu sırasında kaynakları azaltır. Böylece kullanıcıların ihtiyaçlarına göre kaynak kullanımı optimize edilir.
    
    AWS Auto Scaling Grupları, bir veya birden fazla EC2 örneğini yönetmek için oluşturulmuş bir özelliktir. Bu gruplar, Amazon EC2 Auto Scaling tarafından otomatik olarak yaratılır ve yönetilir. Her zaman en iyi performansı sağlamak için otomatik olarak kaynak ölçeklendirmesi yaparlar. Bu sayede uygulamanın performansı etkilenmeden kullanıcıların ihtiyaçlarına cevap verilir.
    
    Auto Scaling Grouplarını oluşturmak için bir **launch template** oluşturulur. Bu template, yeni oluşturulacak instance’lar içni bir template’dir. Örneğin yeni instance’nin tipi, network ayarları…
    
    Daha sonra auto scaling group oluşturulur. Eğer cpu(bir metrik seçilir eşik değer için) kullanımı bir değeri aşarsa, template’de belirlenen ayarlara göre bir instance oluşturulur ve kullanıma sokulur. Aynı şekilde tüm instance’lerin eşik ortalaması bir değerin altına düşerse bir instance kapatılır.
    
    Bir Nodejs uygulamamız olduğunu düşünelim. Malum Nodejs ağır yüklerde çok dayanamayabilir. Bu yüzden autoscaling daha bir önem kazanıyor. İçine nodejs ve gerekli bağımlılıkları kurarak bir server oluşturuyoruz. Ardından bir auto scaling group oluşturuyoruz. Az önceki server’i bu auto-scaling group ile bağlıyoruz. Ancak şu var ki launch template’ler sayesinde, biz ana server’imizi hangi OS ile kurduysak diğer up edilecek server’larda aynı işletim sisteminde olmak zorunda değildir. Artık yüke göre auto-scale olabilir server’imiz.
    
- **ELB (Elastic Load Balancer)**
    
    Load balancer, server’e gelen yükü diğer server’ler ile paylaştırır. Ancak bu, **classic load balancer** mantığıdır. AWS bu mantığı eski olarak görüyor ve bunu önermiyor. **Application load balancer** ismini verdiği bir balancer tipini öneriyor Bu balancer ile **path** bazlı routing yapabiliyoruz. Örneğin; “blog path’ine istek atanlar şu server’e yönlensin, video izleme path’ine istek atanlar şu server’e yönlensin“ diyerek yükleri dağıtıyor aslında. Ancak path kurallarını belirlemeyerek classic load balancer gibi de kullanabiliriz.
    
    Auto Scaling servisinde olduğu gibi yine Nodejs örneği üzerinden gidelim:
    
    Bir Nodejs uygulamamız olduğunu düşünelim. İçine nodejs ve gerekli bağımlılıkları kurarak bir server oluşturuyoruz. Oluştrduğumuz bu server’in bir imagesini(AMI) alıyoruz. Böylece aynı serverden iki tane elde etmiş oluyoruz. Ardından iki auto scaling group oluşturuyoruz. Az önceki server’leri bu iki auto-scaling group ile bir group bir Ec2’ye denk gelecek şekilde bağlıyoruz. Ardından bir ELB oluşturuyoruz. Bu ELB ile iki load balanceri bağlıyoruz. ELB bize bir URL verir. Bu URL artık bizim sitemizin ismi olur. Bu adrese gidenler yüklere göre gerekli server’lere yönlendirilecek. Bu ne anlama gelir?
    
    Bir kullanıcı siteye girdiğinde ilk önce ASG1’e gidecek. Siteye ikinci giren kullanıcı ASG2’ye gidecek. Böylece siteye giren kişi sayısı ikiye bölünüp server yükleri azalacak. Ancak yine de ASG’lerde threshold olarak belirlenen CPU(metrik) değeri aşılırsa yük binen auto scaling group bir instance daha başlatacak. 
    
    Hem auto scaling group hem de ELB kullanarak sistemimizi mikemmelleştiriyoruz 😊
    
    <aside>
    💡 ELB (bizim belirlediğimiz) eğer isteklerden belli sayıda cevap alamazsa bu server unhealthy der ve artık tüm istekleri diğer server’e yönlendirir. Bu istek olayı sadece ELB için değil auto scaling group için de geçerlidir. ASG de attığı isteklere karşılık bulamazsa başka server açar yani scale olur.
    
    </aside>
    

### **5. Cloud Security**

> Cloudwatch ile servislerimize gelen ve onlardan giden bütün trafiği izleyebiliriz. Ayrıca normal (cpu, request…) davranışından farklı bir durum görülmesine duruma karşı alarmlar kurulabilir. Eğer istekler bizim belirlediğimiz bir pick yapacak olursa alarm verir. Böylece olası ataklara karşı sistemimizi izlemiş oluruz.
> 

> CloudTrail ile sistemimizin hareketleri takip edilebilir. CloudTrail bir log sistemidir. AWS üzerinde yaptığımız hareketler bu serviste kaydedilir. Örneğin bir saldırı olduğunda CloudWatch ile hangi saatte bir sapma olduğuna bakılıp CloudTrail ile o saat aralığı incelenip saldırganın hizmetlerde neler yaptığına bakılabilir. Ayrıca eğer hala sistemde aktif ise sistemden bir şekilde uzaklaştırılabilir(ama nasıl olduğunu ya da olacağını bilmiyorum)
> 
- **IAM(Identity Access Management)**
    
    Her kullanıcı her bir servis için farklı farklı yetkiler verebilmemizi sağayan erişim yönetim sistemidir. 4 bileşenden oluşur
    
    - Users: Hesapı kullanabilmesi için oluşturulan kullanıcılardır. Her kullanıcıya detaylı yetkiler verilebilir. Her bir serviste hangi işlemi yapıp yapamayacağına kadar…
    Yetki verilen kullanıcılar [console.aws.amazon.com](http://console.aws.amazon.com) adresinden değil de kendisine verilen başka bir adresten giriş yapar. Kullanıcı oluşturma esnasında eğer programmatic access’i seçmişse  kendisine bir ID ve secret verilir. Bu secret’i saklamak zorundadır çünkü bununla secret ile programmatic olarak giriş yapabilecek. Konsol girişi esnasında kullanabileceği bir password de belirler ve bunu kullanır.
    
    > Root hesabınnda işlemler yapmak tavsiye edilmez. Bunu yerine bir administrator kullanıcısı oluşturulur ve işlemler onunla yapılır.
    > 
    - Groups: Kullanıcılara tek tek yetki vermektense ortak haklara sahip kullanıcılar aynı gruba alınır ve kullanıcılar yerine gruplara yetkiler verilir. Örneğin sadece S3’e ulaşabilecek geliştiriciler için bir grup oluşturulur. Bu gruba katılan herkes bu yetkiye sahip olur.
    - Roles: Roles, kullanıcılara benzerdir. Ancak roller, kullanıcılar yerine uygulamalara izinler sağlar. Örneğin bir EC2 instance’sinin hangi yetkilere sahip olacağını, neler yapıp yapamayacağını belirtir. Örneğin bir EC’ instance’sinin sadece S3 servisine erişimi olabilir. Bunu için role oluşturulur daha sonra EC2 instance’sine gidilerek role ataması yapılır.
    - Policies: Yetki anlamına gelir. Users, groups ve role komponentlerinden bahsederke nde aslında bunu kullandık. AWS tarafından sağlanan default policy’leri user, group ya da rollerimize attach edebiliriz. Ya da kendimiz cutom policy oluşturabiliriz. Hangi serviste ne yetkisi olsun şeklinde detay veririz. Daha sonra artık bu yetki diğer kullanıcılara verilebilir.

**6. Application Integration**

- **SQS (Simple Queue Service)**
    
    Standart olarak SQS queue’si best-effort tipindedir. Yani FIFO mantığı ile de değil de kendisine göre en performanslı olacak şekilde sıralar mesajları. Bu yüzden kuyruğa ilk giren mesajın ilk ulaşacağı garantisi yoktur.
    
    Ama ikinci bir kuyruk tipi FIFO kuyruudur. Bu, klasik şekilde ilk gireni ilk ulaştırır.
    
    **Redrive Policy:** FIFO ya da standart kuyruktan bağımsız olarak bir dead letter kuyruğu vardır. Bu kuyruk FIFO olarak çalışır. Eğer ana kuyrukta başarıyla ulaşamazsa bu mesaj dead letter kuyuğuna push’lanır. Dead letter kuyruğuna girecek olan max  mesaj sayısı belirlenebilir. Redrive policy’e izin verildiğinde dead letter olacak kuyruk için de bir kuyruk eklenmelidir.
    
    **Delay queue:** Gönderilen bir mesaj bir süre boyunca invisible durumda olabilir. Böylece consumer’a daha geç ulaşır. Örneğin bu süre 30sn olarak belirlenirse bütün mesajlar 30 saniye sonra ulaşacaktır. Bu ayar, sqs oluşturma ksımında ayarlanır.
    
    **Long Polling & Short Polling:** Short polling’de; consumer kuyruktaki veriler için kuyruğu yoklar ve veri varsa alır. Long polling’de belirlenen(receive message wait time: max 20sn. Eğer 0sn olarak ayarlanırsa short polling olur) bir süre boyunca consumer kuyruğu sürekli yoklar ve bu süreçte bağlantı açık kalır. Ve eğer mesaj gelirse alır. Long polling, api operasyonlarını yani istek sayısını azalttığı için daha az maliyetlidir.
    
    SQS’in en sık kullanım senaryolarından birisi bir SNS’ten veri almak ve SQS’e bir veri gedliğinde bir Lambda function’unun trigger etmek.
    
- **SNS (Simple Notification Service)**
    
    PubSub modeliyle çalışan bir servistir. Producer bir mesaj publish eder ve ona subscribe olan consumer’lar bunu consume eder. Bu servisle birlikte email, bildirim subscribe’leri de yapılabilir.
    
    Örneğin uygulamamıza “subscribe to our mail newsletter” özelliği eklemek istiyorsak SNS çok güzel bir yapı. Uygulamamızdan SNS’e mail içeriği gönderiririz. SNS de gelen veriyi mail olarak gönderir.
    
    Sık kullanım senaryosu: Bir topic(topic bir veri deposu gibi düşünülebilir. Producer’lerin publish ettiği veri burada toplanır ve ilgili consumer’lar buradan tüketebilir.) oluşturarak üretilen mesajı **topic**’e göndermek ve subscriber’lerin o topic’e bir SQS queue’si yardımıyla bağlanması. Böylece eğer bir service bir mesaj güzelce ulaşmazsa tekrar topic’in tekrar iletme mekanızması ile verinin alındığında emin olunabilir.
    
    Aşağıdaki görselde API gateway ile endpointe gelen bir sipariş oluşturma isteği ile bir lambda function çalışıyor ve gerekli işlemler(db write, read….) yapılıyor. Ardından sipariş bir SNS topic’ine gidiyor. İlgili SNS topic’e üç tane SQS bağlanmış.
    
    > Peki SQS’e ne gerek var, direkt consume edebilirdi SNS’ten?
    > 
    > 
    > Evet bunu yapabilirlerdi ama problemsiz bir şekilde aktarım olsaydı. Bazı sebeplerden dolayı mesaj ulaşmayabilir ya da subscriber o anda çökebilir vs vs..
    > 
    > Ancak araya bir queue koyarsak mesaj kaybedilmez. Bir şekilde mesaj karşı tarafa ulaşamazsa, mesaj zaten oldukça uzun bir süre boyunca kuyrukta bekletileceği için mesaj tekrardan daha sonra alıcıya ulaşabilir. Veri bütünlüğünü korumak için bunu yapıyoruz.
    > 
    
    Queue’ler ile lambdalara ulaşan ürünler farklı işlemlere tabi olabilir.
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2017.png)
    

### 7. Bussiness Aplications

- **SES(Simple Email Server)**
    
    Google, outlook, mailchimp’in olduğu gibi SES de bir SMTP server’dir. Malum SMTP ile mailler taşınır. Bir mail gönderdiğimizde bilgiayarımız bir client’tir. Gireriz ve göndeririz. Peki bir kullanıcı doğrulama, haber bülteni gibi otomatize edilmiş mailleri kim göndericek. Tarayıcıdan elle girip her kullanıcıya tek tek mail mi atacağız? Elbette hayır. Bunun için SMTP Server kullanılır. Bizim yerimize bu server’ler mail gönderir. Aslında email servisleri Postman’a benzetilebilir. Elimizde bir client yoksa server’a istek atmak için Postman kullanırız.
    
    SES de bunu sağlar. Email göndermek için ya verify edilmiş bir domain adresiniz olmalı ya da göndereceğiniz bütün mail adreslerini verify etmeslniz. Elbette ki bu pek mümkün değil. Bunun da çözümü var ancak araştırılmalı.
    

### **8. Database**

- **Redshift**
    
    <aside>
    💡 Warehouse: Farklı kaynaklardan verileri alıp kendi içinde depolayan ve çıktıları kullanıcıya grafikler ve raporlar olarak geri döndüren bir sistemdir.
    
    </aside>
    
    <aside>
    💡 RedShift columnar(sütun bazlı) bir sisteme sahiptir.
    Yani verileri, SQL gibi satır satır değil de her satırın sütunlarını tek bir block içinde olacak şekilde birleştirir. Böylece avg, sum gibi sütun bazlı işlemlerde Redshift çok hızlıdır. Aslında SQL’den ayrılan en büyük farkı budur.
    
    </aside>
    
    <aside>
    💡 Örneğin bir firmamız var ve firmanın, her satıştan kazandığı para bür sütunda tutuluyor. Eğer bunu Redshift’te depolarsak, sum(revenue) dediğimizde bize toplam geliri getirecektir. Ve bu veriyi bizim için görselleştirir.
    
    </aside>
    
    <aside>
    💡 Warehouse, cluster’lardan oluşur. Her bir database aslında bir cluster’dir. Ve cluster’ler, single ve multi node olarak ikiye ayrılır. Single node’da leader node ile compute node aynıdır. Compute node nedir?
    Cluster’a bir sorgu atıldığında bu görev leader node’a gelir. Eğer multi node bir sistemde çalışılıyorsa, leader node görevi, yüke göre compute node’lara dağıtır.
    
    </aside>
    
    <aside>
    💡 Redshift de bir warehouse tipidir.
    
    </aside>
    
    <aside>
    💡 Redshift’e veriler import edilebilir. Örneğin başka bir SQL DB kaynağından export olınan bir veri Redshift’e import edilip okunabilir. Table’ların içleri böyle oluşturulabilir.
    
    [Tutorial: Loading data from Amazon S3 - Amazon Redshift](https://docs.aws.amazon.com/redshift/latest/dg/tutorial-loading-data.html)
    
    </aside>
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2018.png)
    
    <aside>
    💡 SQL workbench benzeri uygulamalar ile Redshift ile bağlantı kurulup sorgu yapılabilir.
    
    </aside>
    

### **9. DevOps**

- **Code Pipeline**
    
    <aside>
    💡 CI/CD kodun geliştirilmesi, test edilmesi ve deploy edilmesi süreçlerini otomatize eden bir araçtır. Bir developer kodun br parçasın üzerinde çalışır. Onu git gibi bir araca commit eder ve kodu test edilir. Bir problem varsa hemen geri bildirim verir ve developer onu düzeltir. Eğer problem yoksa kod, hemen ana kod ile birleşir ve süreç hızlı bir şekilde ilerler. Mümkün hataların önüne geçilir.
    
    </aside>
    
    CI/CD süreci için tasarlanmış bir servistir. Örneğin uzak versiyon kontrol için github kullanılıyorsa code pipeline servisine github bağlanır. Github reposunda herhangi bir değişiklik olursa code pipeline tetiklenir. Eğer code pipeline’a beanstalk bağlıysa beanstalk uygulaması güncellenir.
    
- Code commit/build/deploy
    
    AWS’nin github/gitlab gibi platformlar rakip olabilecek aracıdır. AWS bütün yazılım süreçlerini kendi servisleri ile yönetebilmek için kendi araçlarını yapmıştır.
    

### 10. Web and Mobile

- Amplify
    
    = Firebase
    

### 11. Analytics

- Kinesis
    
    Apache Kafka ile benzer işlemi yapmaktadır. Bir akış içindeki verileri toplayabilir, işleyebilir ve analiz edebiliriz.
# AWS

<aside>
ğŸ’¡ Daha temel olarak bile Ã¶ÄŸrenecek Ã§ok servis var

</aside>

## Architecture

Ä°ki temel yapÄ±dan oluÅŸur:

- Region: DÃ¼nyadaki bÃ¶lgelerdir.
- Availability zone: BÃ¶lgelerdeki server centerâ€™lerdir. Ã–rneÄŸin bir region birden fazla availability zoneâ€™a sahip olabilir.

# Service Domains

### 1. **Compute**

- **EC2**
    
    **BidiÄŸimiz sanal makinelerdir. Ancak gelen veri miktarÄ±na, cpu gereksinimlerineâ€¦ gÃ¶re kendisini up/down scale edebilir. Bu yÃ¼zden esnektir. UygulamamÄ±zÄ± up scale etmemiz gerektiÄŸinde yeni instanceâ€™ler almak yerine tek instanceâ€™ta scale yaparak const efficiency saÄŸlar.**
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled.png)
    
    ### **Instance Types**
    
    1. General Purpose
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%201.png)
    
    1. Compute instance
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%202.png)
    
    1. Memory instance
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%203.png)
    
    1. Storage instances
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%204.png)
    
    1. Gpu instance
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%205.png)
    
    ### Pricing Models
    
    1. On-demand: KullanÄ±cÄ±nÄ±n isteklerine gÃ¶re kiralama yapÄ±lan modeldir. Ã–rneÄŸin, benim iÃ§in 1 saatliÄŸine kirala.
    2. Dedicated: Bu sanal makineler kimseyle paylaÅŸÄ±lmaz. Veriler normalde zaten gÃ¼vendedir ama Ã¶rneÄŸin bir firmaysanÄ±z ve verileriniz sizin iÃ§in Ã§ok Ã¶nemliyse ki Ã¶yledir, kendinize Ã¶zel bir alan ayÄ±rarak sanal makineler kullanÄ±rsÄ±nÄ±z.
    3. On-spot: AÃ§Ä±k artÄ±rma ile sunucu kiralamak gibi bir ÅŸey. BazÄ± instanceâ€™ler aÃ§Ä±k artÄ±rmaya Ã§Ä±kar. En yÃ¼ksek fiyatÄ± veren kiralar. Ancak bu sunucuda depolama yapÄ±lamaz. Sadece uÃ§ucu veriler saklanÄ±r. Ã‡Ã¼nkÃ¼ kiralanan sÃ¼re bittiÄŸinde verilere ulaÅŸmak mÃ¼mkÃ¼n olmayacaktÄ±r.
    4. Reserved: Tamamen size ayrÄ±lmÄ±ÅŸ bir sanal sunucu(instance) verir. Ne cpuâ€™sunu ne de baÅŸka bir ÅŸeyini baÅŸkasÄ± kullanamaz. Bir ev kiralamak gibi
    
    <aside>
    ğŸ’¡ EC2â€™ler bir VPC olmadan internete baÄŸlÄ± olamazlar hatta var olamazlar. Bir aws hesabÄ±nda default bir vpc olduÄŸu iÃ§in EC2â€™ler oluÅŸturulabilir.
    Bir EC2â€™nin internet giriÅŸ Ã§Ä±kÄ±ÅŸ ayarlarÄ±nÄ± (port vs.) yÃ¶netmek iÃ§in security groupâ€™larÄ± dÃ¼zenlemek gerekir. Security groupâ€™lar ise subnetâ€™lere baÄŸlÄ±dÄ±r. Yani EC2â€™nin baÄŸlÄ± olduÄŸu VPCâ€™nin security groupâ€™larÄ± kullanÄ±lÄ±r.
    
    </aside>
    
- **Elastic Beanstalk**
    
    > EC2â€™nin otomatize edilmiÅŸ ÅŸeklidir.
    > 
    - Bir sanal makinenin, bir uygulama iÃ§in gerekli bÃ¼tÃ¼n ortamÄ± hazÄ±r olarak saÄŸlanÄ±r.
    - Ek olarak monitoring, load-balancer, security group araÃ§larÄ± da gelir.
    - Gelen yÃ¼ke gÃ¶re auto-scale olur.
    - Ek olarak verilen ÅŸeyler iÃ§in bir Ã¼cret Ã¶denmez. Sadece harcanan kaynaklar iÃ§in Ã¼cret Ã¶denir.
    - Web hosting iÃ§in kullanÄ±lÄ±r.
    - Ä°stenildiÄŸi zaman infrastructureâ€™de deÄŸiÅŸiklik yapÄ±labilir
    
    **BazÄ± Kavramlar**
    
    Application version: Gitâ€™te olduÄŸu gibi beanstalkâ€™te yapÄ±lan her deÄŸiÅŸiklik versiyonlanÄ±r. Her deÄŸiÅŸikliÄŸin yeni bir kopyasÄ± oluÅŸturulur
    
    Application environment: FarklÄ± Ã§evreler oluÅŸturulur. Yani Ã¶rneÄŸin development iÃ§in farklÄ±, test iÃ§in farklÄ± prduction iÃ§in farklÄ± bir ortam oluÅŸturabiliriz.
    
    Environment health: Environmentâ€™in durumu 4 farklÄ± renklerle sembolize edilir.Passed, failed, heavy failed, being updated
    
    ---
    
    Beanstlk Web server aynÄ± anda sadece bir environment Ã§alÄ±ÅŸtÄ±rabilir. Bu environment, otomatik olarak isteklere gÃ¶re scale olur. EÄŸer trafik yÃ¼ksek ise ve kapasite yetmediyse baÅŸka bir instance daha kullanÄ±ma aÃ§Ä±lÄ±r ve gelen istekler o instance tarafÄ±ndan da iÅŸlenir. EÄŸer kullanÄ±lacak bir ec2 instance yoksa yeni instanceâ€™ler oluÅŸturulur ve kullanÄ±lÄ±r. O instanceâ€™lere de gerekli uygulamalar yÃ¼klenir. Ama bu iÅŸlemler iÃ§in kulanÄ±cÄ± hiÃ§bir iÅŸlem yapmaz. Beanstalk bunu kendisi yÃ¶netir. Beanstalk isteklerin ve iÅŸlemlerin ve metriklerin loglarÄ±nÄ± tutar(host manager). AyrÄ±ca Security Groupâ€™lar tarafÄ±ndan gÃ¼venlik duvarÄ± ve izinler yÃ¶netilri. Default olarak 80 portu aÃ§Ä±ktÄ±r.
    
    Beanstalk Worker server, workerâ€™larÄ± barÄ±ndÄ±ran farklÄ± bir environmenttir. CPU-intensive ya da time-consuming bir istekle karÅŸÄ±laÅŸÄ±rsa bu isteÄŸi bir SQS(simple queue service) yardÄ±mÄ±yla bir worker serverâ€™a geÃ§er. Worker-serverâ€™da iÅŸlem tamamlanÄ±nca tekrar SQS yardÄ±mÄ±yla web serverâ€™a cevap gelir. Werb server da cevabÄ± clienta dÃ¶ndÃ¼rÃ¼r.
    
    ---
    
    Bir environment oluÅŸturulurken bir domain seÃ§ilir. Bu domain eÅŸsizdir ve aslÄ±nda web serverâ€™in url adersidir. local bir uygulamada server iÃ§in [http://localhost:3000](http://localhost:3000) adresine istek atÄ±yorsak aslÄ±nda bu domain de o iÅŸe yarar.
    
    ---
    
    KonfigÃ¼rasiyonlar menÃ¼sÃ¼ne gelerek instance tipi deÄŸiÅŸtirebiliriz. Ã–rneÄŸin t2xlarge gibi
    
- **Lambda**
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%206.png)
    
    - Ä°ÅŸletim sistemine eriÅŸim yetkisi yoktur.(no worries about infrastruct)
    - Bir uygulama deploy edip Ã§alÄ±ÅŸtÄ±rÄ±lamaz. EC2 ve Beanstalk arasÄ±ndaki ana fark budur. Bunun yerine, verilen arkaplan gÃ¶revlerini yapar.
    - Ä°steiÄŸimiz konfigÃ¼rasyonu seÃ§emeyiz. Ä°ÅŸ yÃ¼kÃ¼mÃ¼ze gÃ¶re Lambda bize gerekli altyapÄ±yÄ± saÄŸlar ve konfigÃ¼rasyonu yapar.
    - Lambda, iÃ§inde containerâ€™ler barÄ±ndÄ±rÄ±r. Ä°ÅŸ yÃ¼kÃ¼ne gÃ¶re container sayÄ±sÄ± azaltÄ±lÄ±r ya da artÄ±rÄ±lÄ±r. Containerâ€™ler iÃ§erisinde, ihtiyaÃ§ duyulan bÃ¼tÃ¼m baÄŸÄ±mlÄ±lÄ±klar vardÄ±r.
    - EC2 durdurulup baÅŸlatÄ±lÄ±r ancak Lambdaâ€™nÄ±n bÃ¶yle bir yapÄ±sÄ± yoktur. Ä°stenilen fonksiyon Ã§aÄŸrÄ±ldÄ±ÄŸÄ±nda Ã§alÄ±ÅŸÄ±r ve biter yani event-drivenâ€™dir.
    
    > Diyelim ki bir blog sitemiz var. Bu blog sitemizde gelen isteklerden profil resmi eklemeyi ele alalÄ±m. Profil fotoÄŸraflarÄ±nÄ± iÅŸleyip S3â€™te depolamak istiyoruz. Ä°ÅŸte bu iÅŸemi bir lambda fonksiyonu olarak yapÄ±yoruz. BÃ¶ylece artÄ±k bu iÅŸlem AWSâ€™nin kendi sunucularÄ±nda yapÄ±lacak ve bize sadece istediÄŸimiz sonucu dÃ¶ner.
    > 
    
    > Genelde medya iÅŸleme, yedek alma, verileri analiz etme gibi iÅŸlemler iÃ§in kullanÄ±lÄ±r. Mail gÃ¶nderme iÅŸlemi iÃ§in de kullanÄ±labilir mesela.
    > 
    
    **NodeJs ile nasÄ±l kullanÄ±lÄ±r?**
    
    [AWS Lambda with Node.js: A Complete Getting Started Guide](https://stackify.com/aws-lambda-with-node-js-a-complete-getting-started-guide/)
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%207.png)
    
    > YukarÄ±daki gÃ¶rselin Ã¶zeti:
    - Bir lambda 3 gbâ€™dan daha bÃ¼yÃ¼k memory kullanamaz.
    - Bir lambda en fazla 15 dakika boyunca Ã§alÄ±ÅŸÄ±r. 15 dakikadan sonra fonksiyon durur
    - 100 milisaniyeye kadar bir gecikme olabilir.
    EÄŸer bunlar sizin uygulamanÄ±z iÃ§in Ã¶nemli kÄ±sÄ±tlarsa bunun yerine EC2 tercih etmelisiniz.
    > 

> AWS serverless ekosistemini nodejsâ€™te kullanmak iÃ§in **serverless** frameworkâ€™Ã¼ npm paketi olarak kurulur. Githubâ€™a nasÄ±l eriÅŸiyorsak AWS hesabÄ±na da aynÄ± ÅŸekilde gerekli configâ€™lerin ardaÄ±ndan eriÅŸebiliriz. BÃ¶ylece lambda fonksiyonlarÄ±na eriÅŸebiliriz.
> 

> IAM: AWS hesabÄ±nÄ±n root kullanÄ±cÄ± dÄ±ÅŸÄ±nda eriÅŸim iznine sahip olan kullanÄ±cÄ±lardÄ±r. Kendilerine verilen bir id ve access key ile giriÅŸ yaparlar. AWS programmatic management yetkisine sahip olurlar yani CLIâ€™lar Ã¼zerinden AWS heabÄ±na eriÅŸebilirler. Ancak istenirse AWS anagement consoleâ€™a da giriÅŸ yetkileri verilebilir.
> 

### 2. Strorage

- **EFS(elastic file system)**
    
    Sadece EC2â€™nin kullanabildiÄŸi bir depolama sistemidir. Boyutu, scale olabilir.
    
- **EBS(elastic block storage)**
    
    BildiÄŸimiz sabit disklerdir. Sadece EC2 ile kullanÄ±labilir. Boyutu sabittir. EC2 instanceâ€™sine attach olarak kullanÄ±labilir.
    
- **S3 (simple storage service)**
    - AWSâ€™nin temel depolama sistemidir. Her tÃ¼rlÃ¼ dosya barÄ±nÄ±dÄ±rÄ±labilir. EriÅŸim hÄ±zÄ± yÃ¼ksektir. Dosyalar, klasÃ¶rleme ÅŸeklinde tutulur. Her bir s3 instanceâ€™sine bucket adÄ± verilir.
    
    > Versinoning: S3â€™teki herhangi bir dosyada deÄŸiÅŸiklik yapÄ±ldÄ±ÄŸÄ±nda Gitâ€™te olduÄŸu gibi, deÄŸiÅŸiklik yapÄ±lan bir Ã¶nceki dosya silinmez. DeÄŸiÅŸiklik yapÄ±lmÄ±ÅŸ dosya da sistemde kaydedilir. Bu iki dosyanÄ±n ismi aynÄ±dÄ±r ancak versiyon numaralarÄ± farklÄ±dÄ±r. Bu Ã¶zellik baÅŸlangÄ±Ã§ta kapalÄ±dÄ±r, aÃ§mak gerekir. YanlÄ±ÅŸlÄ±kla dosya silinmesinin de Ã¶nÃ¼ne geÃ§ilmiÅŸ olur.
    > 
    - Lifecycle rule: Versioning aÃ§Ä±k olduÄŸu durumda, versiyonlarÄ±n diÄŸer bir S3 tipine geÃ§mesine izin verir. Mesela ÅŸunu diyebiliriz: Create edildikten 30 gÃ¼n sonra eski versiyonlarÄ±, Glacier tipindeki S3â€™e taÅŸÄ±.
    - Region replication: Bucketâ€™taki verileri bir baÅŸka bÃ¶lgedeki bucketâ€™a(illa bizim bucketâ€™imiz olmasÄ±na gerek yok) replika etmek
    
    <aside>
    ğŸ’¡ Infrequent tipinde bir S3 vardÄ±r. Bu, S3 ve Gracier arasÄ±nda bir eriÅŸim sÃ¼resine sahiptir.
    
    </aside>
    
    > S3 transfer acceleration: Bir dosyanÄ±n Ã§ekilme esnasÄ±nda eÄŸer S3, Ã§ekecek kiÅŸiye uzaksa bir yavaÅŸlÄ±k oluÅŸabilir. Bunun iÃ§in S3 transfer acceleration kullanÄ±lÄ±r.
    > 
    
    <aside>
    ğŸ’¡ Bucket policy oluÅŸturulabilir. BÃ¶ylece gelen isteklerde istek yapan kiÅŸinin yetkis iyoksa iÅŸlem gerÃ§ekleÅŸmez.
    
    </aside>
    
- **S3 Glacier**
    
    S3â€™Ã¼n bir sÄ±nÄ±fÄ±dÄ±r ama farklÄ± bir servis olarak ayrÄ±lmÄ±ÅŸtÄ±r.
    
    SÃ¼rekli olarak ihtiyaÃ§ olmayan verileri tutmak iÃ§in kullanÄ±lÄ±r. ArÅŸiv olarak adlandÄ±rÄ±lÄ±r. Ã‡Ã¼nkÃ¼ arÅŸivdeki kayÄ±tlara sÃ¼rekli ihtiyacÄ±mÄ±z olmaz. Nadiren gider ve bakarÄ±z. Ä°ÅŸte bu yÃ¼zden S3 Glacierâ€™in arama hÄ±zÄ± dÃ¼ÅŸÃ¼ktÃ¼r.
    

### **3. Networking**

- **VPC**
    
    AWS servislerini barÄ±ndÄ±ran bir sanal ortamdÄ±r. Ben bunu Docker networkâ€™lere benzetiyorum ki belki de altyapÄ±sÄ± Docker ile yapÄ±lÄ±yordur ğŸ™‚
    
    Amazon, her kullanÄ±cÄ±ya her bir regionâ€™da default bir VPC atar. Biz frankfurt regionundaki VPCâ€™yi ele alalÄ±m. Bir regionâ€™da birden fazla data center yani availability zone vardÄ±r. Diyelim ki frankfurtta 3 data center var(bu zonelar arasÄ± mesafe 60-100km arasÄ± deÄŸiÅŸir). Her bir zone iÃ§erisinde farklÄ± subnetâ€™ler olur. Ã–rneÄŸin her zone baÅŸÄ±na bir private bir public olmak Ã¼zere 2 subnet ayÄ±rÄ±rsak toplam 3*2=6 tane subnetâ€™imiz olur. Ama bu subnetleri biz kendi ÅŸart ve kaynaklarÄ±mÄ±za gÃ¶re farklÄ± olarak ayarlayabiliriz. Peki bunu neden yapÄ±yoruz? Tek bir subnet olsa ne olur ki?
    
    Diyelim ki biz sadece bir zoneâ€™a subnet koymuÅŸuz. Bir serverâ€™imiz var ve istekler bu subnet Ã¼zerinden geliyor. EÄŸer bir zoneâ€™da bir sÄ±kÄ±ntÄ± yaÅŸanÄ±rsa diÄŸer zoneâ€™lar Ã¼zerinde uygulama hala Ã§alÄ±ÅŸÄ±r halde olacak ve oralardan trafik alÄ±nabilecek.
    
    Ã–rnekte subnetâ€™lere public ve private ismini verdik diye bu subnetâ€™ler public ve private olmaz. BunlarÄ±n public ve private olmasÄ±nÄ± biz, internet gatewayâ€™ler yoluyla internete aÃ§Ä±lmasÄ±ndaki route tableâ€™lar yoluyla internete Ã§Ä±kÄ±ÅŸ tanÄ±mlarÄ±ndan, rotalarÄ±ndan belirliyoruz.
    
    Publi gatewayâ€™lerimizi internet gateway ile el sÄ±kÄ±ÅŸarak internete Ã§Ä±kartÄ±yoruz. Private gatewayâ€™lerimizi ise NAT Gatewayâ€™lerimiz ile internete Ã§Ä±karÄ±yor, giriÅŸleri blokluyoruz.
    
    Ä°ki subnetâ€™in konuÅŸabilmesi iÃ§in route tableâ€™da bir tanÄ±m olmasÄ± gerekir.
    
    Internet gatewayâ€™i VPCâ€™ye attach ediyoruz. Subnetâ€™lerin internet Ã§kÄ±ÅŸÄ±larÄ±nÄ± internet gatewayâ€™e giriÅŸ olarak verdiÄŸimiz az Ã¶nce bahsettiÄŸimiz subnetâ€™ler gerÃ§ekten public oluyor.
    
    NAT gatewayâ€™lerimizi ise herbir public subnetâ€™e koyarÄ±z. Bunlar sayesinde subnetâ€™ler internete Ã§Ä±kar. Peki neden herbirine koyuyoruz? Tek birine koysak olmaz mÄ±ydÄ±? Elbette olurdu. Bu, bizim tasarÄ±mÄ±mÄ±za kalmÄ±ÅŸ bir ÅŸey. Ancak bunu, high-availability iÃ§in yapÄ±yoruz. BÃ¶ylece bir zoneâ€™a bir ÅŸey olduÄŸunda diÄŸer subnetâ€™ler internete Ã§Ä±kabilir. Private subnetten, internete Ã§Ä±kmak isteyenler nat gatewayâ€™e gelir. Nat gatewayâ€™ler de internet gatewayâ€™ler vasÄ±tasÄ±yla internete Ã§Ä±kar.
    
    Network ACL(access control list) ve security grouplar ise hangi resourceâ€™lara eriÅŸilip eriÅŸilemeyeceÄŸini belirler.
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%208.png)
    
- **Direct Connect**
    
    Verilerin public internet Ã¼zerinden gitmesi yerine private tunnel oluÅŸturarak verilerin gizliliÄŸini saÄŸlar. Private VPN ile farklarÄ± vardÄ±r. VPN, public internet Ã¼zerinden ÅŸifreli bir baÄŸlantÄ± kurarken, direct connect yalnÄ±za iki tarafÄ±n kullanabileceÄŸi ek bir sabit aÄŸ kurar.
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%209.png)
    
- **Route53**
    
    TrafiÄŸi redirect yapar. Bir domainden yapÄ±lan istekleri bir aws servisine(bu servis elbette her ÅŸey olmaz. Ã–rneÄŸin API Gateway ya da cloudfrontâ€¦) yÃ¶nlendirir. Bu servisten emin deÄŸilim. YanlÄ±ÅŸ da anlamÄ±ÅŸ olabilirim. Netflix falan kullanÄ±yormuÅŸ.
    GoDaddy, Namecheap gibi basit DNS servisleri ya da Cloudflareâ€™in DNS servisinden farkÄ± Route53â€™Ã¼n dinamik olmasÄ±dÄ±r. IP adresiniz deÄŸiÅŸse bile domainâ€™iniz deÄŸiÅŸmez. AyrÄ±ca Ã¶rneÄŸin bir server Ã§Ã¶kmesi anÄ±da Route53 ile domain serverâ€™e gelen istekleri otomatik olarak baÅŸka bir sunucunuza yÃ¶nlendirebilirsiniz.
    
- **CloudFront**
    
    Ã–rneÄŸin Amerikaâ€™dan Avusturalyaâ€™ya bir web sitesi iÃ§in bir istek attÄ±ÄŸÄ±mÄ±zda web sitesindeki iÃ§erikler taaaa Avusturalyadan gelir. Ve direkt olarak gelmez. Cloudfront ise bizim iÃ§in belli bÃ¶lgelere **edge location**slar kurar. Avusturalyaâ€™daki sitemizdeki iÃ§erikler bize yakÄ±n olan edge locationslarda cacheâ€™lenir.
    
    End user, verinin bulunduÄŸu bir serverâ€™a bir istek gitmek istediÄŸinde Ã¶nce edge locationâ€™lara gider. EÄŸer orada varsa yani daha Ã¶nceden cacheâ€™lenmiÅŸ ise alÄ±r getirir. EÄŸer yoksa ana serverâ€™a gider. Oradan alarak cacheâ€™leyip edge locationâ€™a yazar. Sonra kullanÄ±cÄ±ya veriyi dÃ¶ner.
    
    Cloudfront oluÅŸturulduÄŸunda, bu servisin hangi servise referans edeceÄŸi seÃ§ilir. Ã–rneÄŸin CDN olarak S3 servisini kullanacaksak onu seÃ§eriz. EÄŸer S3 bucketâ€™inin tamamÄ±nÄ± deÄŸil de iÃ§indeki bir klasÃ¶rÃ¼ serve edeceksek onu seÃ§eriz. Gerekli custom ayarlarÄ± yapabilir ve cloudfront oluÅŸtururuz. OluÅŸturulduktan sonra bize eÅŸsiz bir isim verir. Ã–rneÄŸin:
    
    ```jsx
    nb12v3b12p3123lk.cloudfront.net
    ```
    
    Bu adresi kullanarak direkt olarak verileri buradan fetch edebiliriz. Bence her ne kadar doÄŸru bir davranÄ±ÅŸ olmasa da CRUD iÅŸlemlerini de bu adresten yapabiliriz. Ama bunu ayarlardan seÃ§mek gerekir. Ã–rneÄŸin bootstrap CDNâ€™den CSS dosyasÄ±nÄ± Ã§ektiÄŸimiz gibi client tarafÄ±nda resimleri gÃ¶sterirken Ã¶rneÄŸin ÅŸu ÅŸekilde kullanÄ±lÄ±rsa cloudfront bence baÅŸarÄ±lÄ± olur: 
    
    ```jsx
    http://nb12v3b12p3123lk.cloudfront.net/avatar/user-id.jpg
    ```
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2010.png)
    
- API Gateway
    
    REST ya da HTTP API saÄŸlar. Serverless mimarisi dahilinde kullanÄ±lÄ±r genelde
    

### **4. Monitoring and Management**

- **Cloudwatch**
    
    > **Monitoring tool nedir? Ne iÅŸimize yarar?**
    > 
    > 1. Uygulamadaki kullanÄ±cÄ±larÄ±n neler yaptÄ±ÄŸÄ±nÄ± ve trendleri izlemek. Ã–rneÄŸin bir mesajlaÅŸma uygulamanÄ±z var. KullanÄ±cÄ±larÄ±n neler yaptÄ±ÄŸÄ±nÄ±, en Ã§ok hangi iÅŸlemlerin yapÄ±ldÄ±ÄŸÄ±nÄ±, hangilerinin daha az kaynak harcadÄ±ÄŸÄ±nÄ± izleyebilir ve bÃ¶ylece uygulamaya yÃ¶n verebiliriz.
    > 2. Serverâ€™in iÅŸlem yapmadÄ±ÄŸÄ± zamanlarda izleyerek down-scale yapmak ya da kapatmak. Bir uygulamanÄ±z var ve bu uygulama geceleri iÅŸlem yapmÄ±yorsa ya da Ã§ok az yapÄ±yorsa bunu izleyerek geceleri uygulamanÄ±zÄ± kapatabilir ya da down-scale edebilirsiniz. BÃ¶ylece maliyetten kurturulursunuz.
    > 3. Ã‡alÄ±ÅŸan sisteminiz aniden Ã§Ã¶kerse bunun sebebini monitoring tool sayesinde kolayca bulup uygulamayÄ± fix edebilirsiniz. Ã–rneÄŸin bir e-ticaret siteniz varsa Ã§Ã¶kme anÄ±nda baÅŸka sitlere gidebilecek potansiyel mÃ¼ÅŸterileri kaybetmemiÅŸ olursunuz.
    
    <aside>
    ğŸ’¡ Cloudwatch ile ÅŸunlar yapÄ±labilir:
    
    - ile trendleri yani kullanÄ±cÄ± hareketleri izlenebilir.
    - sistem performansÄ±nÄ± izlenebilir
    - Sisteme eriÅŸimlerini log dosyalarÄ±nÄ± depolanabilir
    - Alarmlar kurabilir ve bildirimler gÃ¶nderilir
    - SNS topics, lambda functions gibi aws resourceâ€™larÄ±na eventâ€™ler gÃ¶nderilebilir.
    </aside>
    
    Cloudwatch aslÄ±nda bir **metrik** deposudur.
    
    **Metrik**; herhangi bir amazon servisinin(EC2, EBS, load balancerâ€¦) verileridir(Ã¶rneÄŸin cpu, memory, network kullanÄ±mÄ±â€¦).
    
    Her bir metrik **dimensionlara** sahiptir. Her bir metriÄŸin farklÄ± aÃ§Ä±lardan deÄŸerlendirmesi gibi dÃ¼ÅŸÃ¼nÃ¼lebilir. X metriÄŸinin Y dimensionâ€™u ve Z dimensionâ€™u gibi. Dimensionâ€™lar, metrikleri eÅŸsiz isimlere sahip kÄ±lan bir key-value Ã§ifti gibidir. BÃ¶ylece her dimension iÃ§in bir tablo oluÅŸturulur.
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2011.png)
    
    Ä°statistikler ise toplanan metriklerin tablolarÄ±nÄ±n birleÅŸtirilmesinden oluÅŸan bir tablodur.
    
    Alarmlar sayesinde, belirlenen metrik deÄŸerleri belirlenen deÄŸerlere ulaÅŸtÄ±ÄŸÄ±nda bildirim gÃ¶nderilir ve kullanÄ±cÄ± haberdar edilir ya da diÄŸer aws servisleri tetiklenebilir
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2012.png)
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2013.png)
    
    <aside>
    ğŸ’¡ Cloudwatchâ€™ta bir metrik izlenir. EÄŸer o metrikte bir deÄŸer aÅŸÄ±lÄ±rsa ya da bir anomalÄ± gerÃ§ekleÅŸirse SNS topicâ€™ine bilgi gÃ¶nderilir. SNS topiÄŸi de subscriberâ€™lere bildirim gÃ¶nderir.
    
    </aside>
    
    **CloudWatch Events**
    
    Bir AWS servisinde bir deÄŸiÅŸiklik olduÄŸunda Cloudwatch events sayesinde bundan haberdar olup gerekli aksiyonlarÄ± alabiliriz. Lambda function bir SQSâ€™teki deÄŸiÅŸiklikleri farkedip nasÄ±l aksiyon alÄ±yorsa CloudWatchâ€™de aslÄ±nda bir AWS servisinde olan bir deÄŸiÅŸikliÄŸi farkedip ona gÃ¶re bir iÅŸlem yaptÄ±rabilir.
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2014.png)
    
    YukarÄ±daki use caseâ€™de bir ec2 serverâ€™i kapanÄ±rsa cloudwatch event sayesinde bir lamba functionâ€™u Ã§alÄ±ÅŸarak kapanan serverâ€™in dns kaydÄ±nÄ± route53â€™ten siler.
    
    DiÄŸer bir use-case ise: Bir EC2 instanceâ€™sini kapamak aÃ§mak ya da herhangi yapÄ±lmasÄ± gereken bir iÅŸi zamanlamak. YapÄ±lmasÄ± gereken iÅŸin lambda fonksiyonu oluÅŸturulur. Bu lambda fonksiyonu cloudwatch alarmÄ± sayesinde her gÃ¼n saat 6â€™da Ã§alÄ±ÅŸmak Ã¼zere ayarlanabilir. cloudWATCH ğŸ˜ƒ 
    **CloudWatch Logs**
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2015.png)
    
- **CloudFormation**
    
    Cloudformation, bir JSON/YAML dosyasÄ± ile aws kaynaklarÄ±nÄ± tek bir elden kolayca yÃ¶netmeyi saÄŸlayan bir servistir. Bir json dosyasÄ± iÃ§ine, proje ya da uygulamada kullanÄ±lacak olan servisler ve bunlarÄ±n konfigÃ¼rasyonlarÄ± ve security groupâ€™larÄ± yazÄ±lÄ±r. BÃ¼tÃ¼n bu ayarlardan sonra bir stack oluÅŸturulmuÅŸ olur. Bu stack, bir S3 bucket olarak depolanÄ±r. Ä°stendÄŸi zaman stack silinerek, stackâ€™e baÄŸlÄ± kaynaklarÄ±n da silinnmesi saÄŸlanÄ±r.
    
    Json dosyasÄ± iÃ§inde ÅŸu bilgiler yer alabilir:
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2016.png)
    
    Parameter olarak servislerde kullanÄ±lacak olan bilgiler girilir. Ã–rneÄŸin DB name, DB password, ssh keysâ€¦
    
    Bu servis bir json dosyasÄ±ndan ibaret olsa da json dosyasÄ±na ihtiyaÃ§ duyulmadan drag-drop yÃ¶ntemiyle de kolayca stack oluÅŸturulabilir.
    
    ClÄ±udformation sayesinde kolaylÄ±kla bir EC2 oluÅŸturulup iÃ§inde Nodejs ve gerekli baÄŸÄ±mlÄ±lÄ±klar kurularak uyglama ayaÄŸa kaldÄ±rÄ±labilir.
    
    AslÄ±nda cloudformationâ€™u docker-compose ya da CI/CD dosyalarÄ±na benzetebiliriz. Docker compose dosyasÄ±nda da gerekli servisleri saÄŸlayarak uygulamayÄ± up edebiliriz.
    
    Benzer ÅŸekilde Ã¶rneÄŸin Gitlab CI dosyasÄ±nda da uygulama kurulduktan sonra server iÃ§inde Ã§alÄ±ÅŸtÄ±rÄ±lacak kodlarÄ± yazabiliyoruz. Cloudformationâ€™da da EC2 kurup iÃ§ine kodlar yazarak kurmak istediklerimizi kurarÄ±z
    
    **Peki ben CloudFormationâ€™u nerede kullandÄ±m?**
    
    Serverless frameworkâ€™te kullandÄ±m. Serverless.yml dosyasÄ±na yazÄ±lan kodlar deploy edildiÄŸinde aslÄ±nda bir cloudformation stack oluÅŸturulur ve serverless.yml dosyasÄ± ile o stack json dosyasÄ±nÄ± yÃ¶netiriz. AWS SAM de benzer mantÄ±kla Ã§alÄ±ÅŸmaktadÄ±r.
    

<aside>
ğŸ’¡ **Snapshot**: Bir EC2 serverâ€™indeki datalarÄ±n anlÄ±k bir kopyasÄ±nÄ± almaktÄ±r. Bu kopyalanana data bir EBS volumeâ€™sinde tutulur. Bir server kurulduÄŸunda bunun baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± yÃ¼klemek zaman alÄ±r. Bunun iÃ§in kurduktan sonra bunun bir kopyasÄ±nÄ± alÄ±rsak serverâ€™a bir ÅŸey olursa tekrar kurmak zorunda kalmayÄ±z.

</aside>

<aside>
ğŸ’¡ AMI(Amazon Machine Image): Bir EC2 serverâ€™inin anlÄ±k kopyasÄ±nÄ± almaktÄ±r. Snapshotâ€™tan farkÄ± Ã§alÄ±ÅŸtÄ±rÄ±labilir olmasÄ±dÄ±r. Bir EC2 server nasÄ±l up edilebiliyorsa bir AMI de up edilebilir.

</aside>

- **AutoScaling**
    
    **AWS Auto Scaling ve AWS Auto Scaling GruplarÄ±**
    
    AWS Auto Scaling, uygulama dÃ¼zeyinde Ã¶lÃ§eklendirme iÃ§in hizmet verir. Bu hizmet sayesinde uygulamanÄ±z otomatik olarak yÃ¼ksek kullanÄ±m yoÄŸunluÄŸu sÄ±rasÄ±nda daha fazla kaynak alÄ±r veya dÃ¼ÅŸÃ¼k kullanÄ±m yoÄŸunluÄŸu sÄ±rasÄ±nda kaynaklarÄ± azaltÄ±r. BÃ¶ylece kullanÄ±cÄ±larÄ±n ihtiyaÃ§larÄ±na gÃ¶re kaynak kullanÄ±mÄ± optimize edilir.
    
    AWS Auto Scaling GruplarÄ±, bir veya birden fazla EC2 Ã¶rneÄŸini yÃ¶netmek iÃ§in oluÅŸturulmuÅŸ bir Ã¶zelliktir. Bu gruplar, Amazon EC2 Auto Scaling tarafÄ±ndan otomatik olarak yaratÄ±lÄ±r ve yÃ¶netilir. Her zaman en iyi performansÄ± saÄŸlamak iÃ§in otomatik olarak kaynak Ã¶lÃ§eklendirmesi yaparlar. Bu sayede uygulamanÄ±n performansÄ± etkilenmeden kullanÄ±cÄ±larÄ±n ihtiyaÃ§larÄ±na cevap verilir.
    
    Auto Scaling GrouplarÄ±nÄ± oluÅŸturmak iÃ§in bir **launch template** oluÅŸturulur. Bu template, yeni oluÅŸturulacak instanceâ€™lar iÃ§ni bir templateâ€™dir. Ã–rneÄŸin yeni instanceâ€™nin tipi, network ayarlarÄ±â€¦
    
    Daha sonra auto scaling group oluÅŸturulur. EÄŸer cpu(bir metrik seÃ§ilir eÅŸik deÄŸer iÃ§in) kullanÄ±mÄ± bir deÄŸeri aÅŸarsa, templateâ€™de belirlenen ayarlara gÃ¶re bir instance oluÅŸturulur ve kullanÄ±ma sokulur. AynÄ± ÅŸekilde tÃ¼m instanceâ€™lerin eÅŸik ortalamasÄ± bir deÄŸerin altÄ±na dÃ¼ÅŸerse bir instance kapatÄ±lÄ±r.
    
    Bir Nodejs uygulamamÄ±z olduÄŸunu dÃ¼ÅŸÃ¼nelim. Malum Nodejs aÄŸÄ±r yÃ¼klerde Ã§ok dayanamayabilir. Bu yÃ¼zden autoscaling daha bir Ã¶nem kazanÄ±yor. Ä°Ã§ine nodejs ve gerekli baÄŸÄ±mlÄ±lÄ±klarÄ± kurarak bir server oluÅŸturuyoruz. ArdÄ±ndan bir auto scaling group oluÅŸturuyoruz. Az Ã¶nceki serverâ€™i bu auto-scaling group ile baÄŸlÄ±yoruz. Ancak ÅŸu var ki launch templateâ€™ler sayesinde, biz ana serverâ€™imizi hangi OS ile kurduysak diÄŸer up edilecek serverâ€™larda aynÄ± iÅŸletim sisteminde olmak zorunda deÄŸildir. ArtÄ±k yÃ¼ke gÃ¶re auto-scale olabilir serverâ€™imiz.
    
- **ELB (Elastic Load Balancer)**
    
    Load balancer, serverâ€™e gelen yÃ¼kÃ¼ diÄŸer serverâ€™ler ile paylaÅŸtÄ±rÄ±r. Ancak bu, **classic load balancer** mantÄ±ÄŸÄ±dÄ±r. AWS bu mantÄ±ÄŸÄ± eski olarak gÃ¶rÃ¼yor ve bunu Ã¶nermiyor. **Application load balancer** ismini verdiÄŸi bir balancer tipini Ã¶neriyor Bu balancer ile **path** bazlÄ± routing yapabiliyoruz. Ã–rneÄŸin; â€œblog pathâ€™ine istek atanlar ÅŸu serverâ€™e yÃ¶nlensin, video izleme pathâ€™ine istek atanlar ÅŸu serverâ€™e yÃ¶nlensinâ€œ diyerek yÃ¼kleri daÄŸÄ±tÄ±yor aslÄ±nda. Ancak path kurallarÄ±nÄ± belirlemeyerek classic load balancer gibi de kullanabiliriz.
    
    Auto Scaling servisinde olduÄŸu gibi yine Nodejs Ã¶rneÄŸi Ã¼zerinden gidelim:
    
    Bir Nodejs uygulamamÄ±z olduÄŸunu dÃ¼ÅŸÃ¼nelim. Ä°Ã§ine nodejs ve gerekli baÄŸÄ±mlÄ±lÄ±klarÄ± kurarak bir server oluÅŸturuyoruz. OluÅŸtrduÄŸumuz bu serverâ€™in bir imagesini(AMI) alÄ±yoruz. BÃ¶ylece aynÄ± serverden iki tane elde etmiÅŸ oluyoruz. ArdÄ±ndan iki auto scaling group oluÅŸturuyoruz. Az Ã¶nceki serverâ€™leri bu iki auto-scaling group ile bir group bir Ec2â€™ye denk gelecek ÅŸekilde baÄŸlÄ±yoruz. ArdÄ±ndan bir ELB oluÅŸturuyoruz. Bu ELB ile iki load balanceri baÄŸlÄ±yoruz. ELB bize bir URL verir. Bu URL artÄ±k bizim sitemizin ismi olur. Bu adrese gidenler yÃ¼klere gÃ¶re gerekli serverâ€™lere yÃ¶nlendirilecek. Bu ne anlama gelir?
    
    Bir kullanÄ±cÄ± siteye girdiÄŸinde ilk Ã¶nce ASG1â€™e gidecek. Siteye ikinci giren kullanÄ±cÄ± ASG2â€™ye gidecek. BÃ¶ylece siteye giren kiÅŸi sayÄ±sÄ± ikiye bÃ¶lÃ¼nÃ¼p server yÃ¼kleri azalacak. Ancak yine de ASGâ€™lerde threshold olarak belirlenen CPU(metrik) deÄŸeri aÅŸÄ±lÄ±rsa yÃ¼k binen auto scaling group bir instance daha baÅŸlatacak. 
    
    Hem auto scaling group hem de ELB kullanarak sistemimizi mikemmelleÅŸtiriyoruz ğŸ˜Š
    
    <aside>
    ğŸ’¡ ELB (bizim belirlediÄŸimiz) eÄŸer isteklerden belli sayÄ±da cevap alamazsa bu server unhealthy der ve artÄ±k tÃ¼m istekleri diÄŸer serverâ€™e yÃ¶nlendirir. Bu istek olayÄ± sadece ELB iÃ§in deÄŸil auto scaling group iÃ§in de geÃ§erlidir. ASG de attÄ±ÄŸÄ± isteklere karÅŸÄ±lÄ±k bulamazsa baÅŸka server aÃ§ar yani scale olur.
    
    </aside>
    

### **5. Cloud Security**

> Cloudwatch ile servislerimize gelen ve onlardan giden bÃ¼tÃ¼n trafiÄŸi izleyebiliriz. AyrÄ±ca normal (cpu, requestâ€¦) davranÄ±ÅŸÄ±ndan farklÄ± bir durum gÃ¶rÃ¼lmesine duruma karÅŸÄ± alarmlar kurulabilir. EÄŸer istekler bizim belirlediÄŸimiz bir pick yapacak olursa alarm verir. BÃ¶ylece olasÄ± ataklara karÅŸÄ± sistemimizi izlemiÅŸ oluruz.
> 

> CloudTrail ile sistemimizin hareketleri takip edilebilir. CloudTrail bir log sistemidir. AWS Ã¼zerinde yaptÄ±ÄŸÄ±mÄ±z hareketler bu serviste kaydedilir. Ã–rneÄŸin bir saldÄ±rÄ± olduÄŸunda CloudWatch ile hangi saatte bir sapma olduÄŸuna bakÄ±lÄ±p CloudTrail ile o saat aralÄ±ÄŸÄ± incelenip saldÄ±rganÄ±n hizmetlerde neler yaptÄ±ÄŸÄ±na bakÄ±labilir. AyrÄ±ca eÄŸer hala sistemde aktif ise sistemden bir ÅŸekilde uzaklaÅŸtÄ±rÄ±labilir(ama nasÄ±l olduÄŸunu ya da olacaÄŸÄ±nÄ± bilmiyorum)
> 
- **IAM(Identity Access Management)**
    
    Her kullanÄ±cÄ± her bir servis iÃ§in farklÄ± farklÄ± yetkiler verebilmemizi saÄŸayan eriÅŸim yÃ¶netim sistemidir. 4 bileÅŸenden oluÅŸur
    
    - Users: HesapÄ± kullanabilmesi iÃ§in oluÅŸturulan kullanÄ±cÄ±lardÄ±r. Her kullanÄ±cÄ±ya detaylÄ± yetkiler verilebilir. Her bir serviste hangi iÅŸlemi yapÄ±p yapamayacaÄŸÄ±na kadarâ€¦
    Yetki verilen kullanÄ±cÄ±lar [console.aws.amazon.com](http://console.aws.amazon.com) adresinden deÄŸil de kendisine verilen baÅŸka bir adresten giriÅŸ yapar. KullanÄ±cÄ± oluÅŸturma esnasÄ±nda eÄŸer programmatic accessâ€™i seÃ§miÅŸse  kendisine bir ID ve secret verilir. Bu secretâ€™i saklamak zorundadÄ±r Ã§Ã¼nkÃ¼ bununla secret ile programmatic olarak giriÅŸ yapabilecek. Konsol giriÅŸi esnasÄ±nda kullanabileceÄŸi bir password de belirler ve bunu kullanÄ±r.
    
    > Root hesabÄ±nnda iÅŸlemler yapmak tavsiye edilmez. Bunu yerine bir administrator kullanÄ±cÄ±sÄ± oluÅŸturulur ve iÅŸlemler onunla yapÄ±lÄ±r.
    > 
    - Groups: KullanÄ±cÄ±lara tek tek yetki vermektense ortak haklara sahip kullanÄ±cÄ±lar aynÄ± gruba alÄ±nÄ±r ve kullanÄ±cÄ±lar yerine gruplara yetkiler verilir. Ã–rneÄŸin sadece S3â€™e ulaÅŸabilecek geliÅŸtiriciler iÃ§in bir grup oluÅŸturulur. Bu gruba katÄ±lan herkes bu yetkiye sahip olur.
    - Roles: Roles, kullanÄ±cÄ±lara benzerdir. Ancak roller, kullanÄ±cÄ±lar yerine uygulamalara izinler saÄŸlar. Ã–rneÄŸin bir EC2 instanceâ€™sinin hangi yetkilere sahip olacaÄŸÄ±nÄ±, neler yapÄ±p yapamayacaÄŸÄ±nÄ± belirtir. Ã–rneÄŸin bir ECâ€™ instanceâ€™sinin sadece S3 servisine eriÅŸimi olabilir. Bunu iÃ§in role oluÅŸturulur daha sonra EC2 instanceâ€™sine gidilerek role atamasÄ± yapÄ±lÄ±r.
    - Policies: Yetki anlamÄ±na gelir. Users, groups ve role komponentlerinden bahsederke nde aslÄ±nda bunu kullandÄ±k. AWS tarafÄ±ndan saÄŸlanan default policyâ€™leri user, group ya da rollerimize attach edebiliriz. Ya da kendimiz cutom policy oluÅŸturabiliriz. Hangi serviste ne yetkisi olsun ÅŸeklinde detay veririz. Daha sonra artÄ±k bu yetki diÄŸer kullanÄ±cÄ±lara verilebilir.

**6. Application Integration**

- **SQS (Simple Queue Service)**
    
    Standart olarak SQS queueâ€™si best-effort tipindedir. Yani FIFO mantÄ±ÄŸÄ± ile de deÄŸil de kendisine gÃ¶re en performanslÄ± olacak ÅŸekilde sÄ±ralar mesajlarÄ±. Bu yÃ¼zden kuyruÄŸa ilk giren mesajÄ±n ilk ulaÅŸacaÄŸÄ± garantisi yoktur.
    
    Ama ikinci bir kuyruk tipi FIFO kuyruudur. Bu, klasik ÅŸekilde ilk gireni ilk ulaÅŸtÄ±rÄ±r.
    
    **Redrive Policy:** FIFO ya da standart kuyruktan baÄŸÄ±msÄ±z olarak bir dead letter kuyruÄŸu vardÄ±r. Bu kuyruk FIFO olarak Ã§alÄ±ÅŸÄ±r. EÄŸer ana kuyrukta baÅŸarÄ±yla ulaÅŸamazsa bu mesaj dead letter kuyuÄŸuna pushâ€™lanÄ±r. Dead letter kuyruÄŸuna girecek olan max  mesaj sayÄ±sÄ± belirlenebilir. Redrive policyâ€™e izin verildiÄŸinde dead letter olacak kuyruk iÃ§in de bir kuyruk eklenmelidir.
    
    **Delay queue:** GÃ¶nderilen bir mesaj bir sÃ¼re boyunca invisible durumda olabilir. BÃ¶ylece consumerâ€™a daha geÃ§ ulaÅŸÄ±r. Ã–rneÄŸin bu sÃ¼re 30sn olarak belirlenirse bÃ¼tÃ¼n mesajlar 30 saniye sonra ulaÅŸacaktÄ±r. Bu ayar, sqs oluÅŸturma ksÄ±mÄ±nda ayarlanÄ±r.
    
    **Long Polling & Short Polling:** Short pollingâ€™de; consumer kuyruktaki veriler iÃ§in kuyruÄŸu yoklar ve veri varsa alÄ±r. Long pollingâ€™de belirlenen(receive message wait time: max 20sn. EÄŸer 0sn olarak ayarlanÄ±rsa short polling olur) bir sÃ¼re boyunca consumer kuyruÄŸu sÃ¼rekli yoklar ve bu sÃ¼reÃ§te baÄŸlantÄ± aÃ§Ä±k kalÄ±r. Ve eÄŸer mesaj gelirse alÄ±r. Long polling, api operasyonlarÄ±nÄ± yani istek sayÄ±sÄ±nÄ± azalttÄ±ÄŸÄ± iÃ§in daha az maliyetlidir.
    
    SQSâ€™in en sÄ±k kullanÄ±m senaryolarÄ±ndan birisi bir SNSâ€™ten veri almak ve SQSâ€™e bir veri gedliÄŸinde bir Lambda functionâ€™unun trigger etmek.
    
- **SNS (Simple Notification Service)**
    
    PubSub modeliyle Ã§alÄ±ÅŸan bir servistir. Producer bir mesaj publish eder ve ona subscribe olan consumerâ€™lar bunu consume eder. Bu servisle birlikte email, bildirim subscribeâ€™leri de yapÄ±labilir.
    
    Ã–rneÄŸin uygulamamÄ±za â€œsubscribe to our mail newsletterâ€ Ã¶zelliÄŸi eklemek istiyorsak SNS Ã§ok gÃ¼zel bir yapÄ±. UygulamamÄ±zdan SNSâ€™e mail iÃ§eriÄŸi gÃ¶nderiririz. SNS de gelen veriyi mail olarak gÃ¶nderir.
    
    SÄ±k kullanÄ±m senaryosu: Bir topic(topic bir veri deposu gibi dÃ¼ÅŸÃ¼nÃ¼lebilir. Producerâ€™lerin publish ettiÄŸi veri burada toplanÄ±r ve ilgili consumerâ€™lar buradan tÃ¼ketebilir.) oluÅŸturarak Ã¼retilen mesajÄ± **topic**â€™e gÃ¶ndermek ve subscriberâ€™lerin o topicâ€™e bir SQS queueâ€™si yardÄ±mÄ±yla baÄŸlanmasÄ±. BÃ¶ylece eÄŸer bir service bir mesaj gÃ¼zelce ulaÅŸmazsa tekrar topicâ€™in tekrar iletme mekanÄ±zmasÄ± ile verinin alÄ±ndÄ±ÄŸÄ±nda emin olunabilir.
    
    AÅŸaÄŸÄ±daki gÃ¶rselde API gateway ile endpointe gelen bir sipariÅŸ oluÅŸturma isteÄŸi ile bir lambda function Ã§alÄ±ÅŸÄ±yor ve gerekli iÅŸlemler(db write, readâ€¦.) yapÄ±lÄ±yor. ArdÄ±ndan sipariÅŸ bir SNS topicâ€™ine gidiyor. Ä°lgili SNS topicâ€™e Ã¼Ã§ tane SQS baÄŸlanmÄ±ÅŸ.
    
    > Peki SQSâ€™e ne gerek var, direkt consume edebilirdi SNSâ€™ten?
    > 
    > 
    > Evet bunu yapabilirlerdi ama problemsiz bir ÅŸekilde aktarÄ±m olsaydÄ±. BazÄ± sebeplerden dolayÄ± mesaj ulaÅŸmayabilir ya da subscriber o anda Ã§Ã¶kebilir vs vs..
    > 
    > Ancak araya bir queue koyarsak mesaj kaybedilmez. Bir ÅŸekilde mesaj karÅŸÄ± tarafa ulaÅŸamazsa, mesaj zaten oldukÃ§a uzun bir sÃ¼re boyunca kuyrukta bekletileceÄŸi iÃ§in mesaj tekrardan daha sonra alÄ±cÄ±ya ulaÅŸabilir. Veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ korumak iÃ§in bunu yapÄ±yoruz.
    > 
    
    Queueâ€™ler ile lambdalara ulaÅŸan Ã¼rÃ¼nler farklÄ± iÅŸlemlere tabi olabilir.
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2017.png)
    

### 7. Bussiness Aplications

- **SES(Simple Email Server)**
    
    Google, outlook, mailchimpâ€™in olduÄŸu gibi SES de bir SMTP serverâ€™dir. Malum SMTP ile mailler taÅŸÄ±nÄ±r. Bir mail gÃ¶nderdiÄŸimizde bilgiayarÄ±mÄ±z bir clientâ€™tir. Gireriz ve gÃ¶ndeririz. Peki bir kullanÄ±cÄ± doÄŸrulama, haber bÃ¼lteni gibi otomatize edilmiÅŸ mailleri kim gÃ¶ndericek. TarayÄ±cÄ±dan elle girip her kullanÄ±cÄ±ya tek tek mail mi atacaÄŸÄ±z? Elbette hayÄ±r. Bunun iÃ§in SMTP Server kullanÄ±lÄ±r. Bizim yerimize bu serverâ€™ler mail gÃ¶nderir. AslÄ±nda email servisleri Postmanâ€™a benzetilebilir. Elimizde bir client yoksa serverâ€™a istek atmak iÃ§in Postman kullanÄ±rÄ±z.
    
    SES de bunu saÄŸlar. Email gÃ¶ndermek iÃ§in ya verify edilmiÅŸ bir domain adresiniz olmalÄ± ya da gÃ¶ndereceÄŸiniz bÃ¼tÃ¼n mail adreslerini verify etmeslniz. Elbette ki bu pek mÃ¼mkÃ¼n deÄŸil. Bunun da Ã§Ã¶zÃ¼mÃ¼ var ancak araÅŸtÄ±rÄ±lmalÄ±.
    

### **8. Database**

- **Redshift**
    
    <aside>
    ğŸ’¡ Warehouse: FarklÄ± kaynaklardan verileri alÄ±p kendi iÃ§inde depolayan ve Ã§Ä±ktÄ±larÄ± kullanÄ±cÄ±ya grafikler ve raporlar olarak geri dÃ¶ndÃ¼ren bir sistemdir.
    
    </aside>
    
    <aside>
    ğŸ’¡ RedShift columnar(sÃ¼tun bazlÄ±) bir sisteme sahiptir.
    Yani verileri, SQL gibi satÄ±r satÄ±r deÄŸil de her satÄ±rÄ±n sÃ¼tunlarÄ±nÄ± tek bir block iÃ§inde olacak ÅŸekilde birleÅŸtirir. BÃ¶ylece avg, sum gibi sÃ¼tun bazlÄ± iÅŸlemlerde Redshift Ã§ok hÄ±zlÄ±dÄ±r. AslÄ±nda SQLâ€™den ayrÄ±lan en bÃ¼yÃ¼k farkÄ± budur.
    
    </aside>
    
    <aside>
    ğŸ’¡ Ã–rneÄŸin bir firmamÄ±z var ve firmanÄ±n, her satÄ±ÅŸtan kazandÄ±ÄŸÄ± para bÃ¼r sÃ¼tunda tutuluyor. EÄŸer bunu Redshiftâ€™te depolarsak, sum(revenue) dediÄŸimizde bize toplam geliri getirecektir. Ve bu veriyi bizim iÃ§in gÃ¶rselleÅŸtirir.
    
    </aside>
    
    <aside>
    ğŸ’¡ Warehouse, clusterâ€™lardan oluÅŸur. Her bir database aslÄ±nda bir clusterâ€™dir. Ve clusterâ€™ler, single ve multi node olarak ikiye ayrÄ±lÄ±r. Single nodeâ€™da leader node ile compute node aynÄ±dÄ±r. Compute node nedir?
    Clusterâ€™a bir sorgu atÄ±ldÄ±ÄŸÄ±nda bu gÃ¶rev leader nodeâ€™a gelir. EÄŸer multi node bir sistemde Ã§alÄ±ÅŸÄ±lÄ±yorsa, leader node gÃ¶revi, yÃ¼ke gÃ¶re compute nodeâ€™lara daÄŸÄ±tÄ±r.
    
    </aside>
    
    <aside>
    ğŸ’¡ Redshift de bir warehouse tipidir.
    
    </aside>
    
    <aside>
    ğŸ’¡ Redshiftâ€™e veriler import edilebilir. Ã–rneÄŸin baÅŸka bir SQL DB kaynaÄŸÄ±ndan export olÄ±nan bir veri Redshiftâ€™e import edilip okunabilir. Tableâ€™larÄ±n iÃ§leri bÃ¶yle oluÅŸturulabilir.
    
    [Tutorial: Loading data from Amazon S3 - Amazon Redshift](https://docs.aws.amazon.com/redshift/latest/dg/tutorial-loading-data.html)
    
    </aside>
    
    ![Untitled](AWS%20a0722a1f32914820adf35881d1275c7c/Untitled%2018.png)
    
    <aside>
    ğŸ’¡ SQL workbench benzeri uygulamalar ile Redshift ile baÄŸlantÄ± kurulup sorgu yapÄ±labilir.
    
    </aside>
    

### **9. DevOps**

- **Code Pipeline**
    
    <aside>
    ğŸ’¡ CI/CD kodun geliÅŸtirilmesi, test edilmesi ve deploy edilmesi sÃ¼reÃ§lerini otomatize eden bir araÃ§tÄ±r. Bir developer kodun br parÃ§asÄ±n Ã¼zerinde Ã§alÄ±ÅŸÄ±r. Onu git gibi bir araca commit eder ve kodu test edilir. Bir problem varsa hemen geri bildirim verir ve developer onu dÃ¼zeltir. EÄŸer problem yoksa kod, hemen ana kod ile birleÅŸir ve sÃ¼reÃ§ hÄ±zlÄ± bir ÅŸekilde ilerler. MÃ¼mkÃ¼n hatalarÄ±n Ã¶nÃ¼ne geÃ§ilir.
    
    </aside>
    
    CI/CD sÃ¼reci iÃ§in tasarlanmÄ±ÅŸ bir servistir. Ã–rneÄŸin uzak versiyon kontrol iÃ§in github kullanÄ±lÄ±yorsa code pipeline servisine github baÄŸlanÄ±r. Github reposunda herhangi bir deÄŸiÅŸiklik olursa code pipeline tetiklenir. EÄŸer code pipelineâ€™a beanstalk baÄŸlÄ±ysa beanstalk uygulamasÄ± gÃ¼ncellenir.
    
- Code commit/build/deploy
    
    AWSâ€™nin github/gitlab gibi platformlar rakip olabilecek aracÄ±dÄ±r. AWS bÃ¼tÃ¼n yazÄ±lÄ±m sÃ¼reÃ§lerini kendi servisleri ile yÃ¶netebilmek iÃ§in kendi araÃ§larÄ±nÄ± yapmÄ±ÅŸtÄ±r.
    

### 10. Web and Mobile

- Amplify
    
    = Firebase
    

### 11. Analytics

- Kinesis
    
    Apache Kafka ile benzer iÅŸlemi yapmaktadÄ±r. Bir akÄ±ÅŸ iÃ§indeki verileri toplayabilir, iÅŸleyebilir ve analiz edebiliriz.